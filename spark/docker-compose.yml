version: "3.6"
volumes:
  shared-workspace:
    name: "hadoop-distributed-file-system"
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ../dfs
services:
  jupyterlab:
    image: jupyterlab
    container_name: jupyterlab
    ports:
      - 8889:8888
    volumes:
      - shared-workspace:/opt/workspace
    command: ["bash", "-c", "chmod +x ./run_notebooks.sh && ./run_notebooks.sh && jupyter lab --ip=0.0.0.0 --port=8888 --allow-root --NotebookApp.token="]
  spark-master:
    image: spark-master
    container_name: spark-master
    ports:
      - 8080:8080
      - 7077:7077
    volumes:
      - shared-workspace:/opt/workspace
  spark-worker:
    image: spark-worker
    environment:
      - SPARK_WORKER_CORES=1
      - SPARK_WORKER_MEMORY=1024m
    ports:
      - "0:4040"  # Allow Docker to dynamically allocate the host port for the worker UI
      - "0:18080"  # Allow Docker to dynamically allocate the host port for the history server
    volumes:
      - shared-workspace:/opt/workspace
    depends_on:
      - spark-master 
    deploy:
      mode: replicated
      replicas: ${SPARK_WORKER_REPLICAS}
